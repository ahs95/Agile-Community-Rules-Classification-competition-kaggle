{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"sourceType":"competition"},{"sourceId":591796,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":442749,"modelId":459283}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-27T14:48:15.512732Z","iopub.execute_input":"2025-09-27T14:48:15.512943Z","iopub.status.idle":"2025-09-27T14:48:17.781905Z","shell.execute_reply.started":"2025-09-27T14:48:15.512924Z","shell.execute_reply":"2025-09-27T14:48:17.780972Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/modernbert-base-trained/pytorch/default/1/model/config.json\n/kaggle/input/modernbert-base-trained/pytorch/default/1/model/trainer_state.json\n/kaggle/input/modernbert-base-trained/pytorch/default/1/model/training_args.bin\n/kaggle/input/modernbert-base-trained/pytorch/default/1/model/tokenizer.json\n/kaggle/input/modernbert-base-trained/pytorch/default/1/model/tokenizer_config.json\n/kaggle/input/modernbert-base-trained/pytorch/default/1/model/scaler.pt\n/kaggle/input/modernbert-base-trained/pytorch/default/1/model/scheduler.pt\n/kaggle/input/modernbert-base-trained/pytorch/default/1/model/model.safetensors\n/kaggle/input/modernbert-base-trained/pytorch/default/1/model/special_tokens_map.json\n/kaggle/input/modernbert-base-trained/pytorch/default/1/model/optimizer.pt\n/kaggle/input/modernbert-base-trained/pytorch/default/1/model/rng_state.pth\n/kaggle/input/jigsaw-agile-community-rules/sample_submission.csv\n/kaggle/input/jigsaw-agile-community-rules/train.csv\n/kaggle/input/jigsaw-agile-community-rules/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T14:48:17.784063Z","iopub.execute_input":"2025-09-27T14:48:17.784482Z","iopub.status.idle":"2025-09-27T14:48:28.340480Z","shell.execute_reply.started":"2025-09-27T14:48:17.784458Z","shell.execute_reply":"2025-09-27T14:48:28.339432Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/jigsaw-agile-community-rules/test.csv')\n\n# Combine text fields for each sample\ndef combine_text_fields(row):\n    return f\"Comment: {row['body']}\\nRule: {row['rule']}\\nPositive Example 1: {row['positive_example_1']}\\nPositive Example 2: {row['positive_example_2']}\\nNegative Example 1: {row['negative_example_1']}\\nNegative Example 2: {row['negative_example_2']}\"\n\ntest_df['combined_text'] = test_df.apply(combine_text_fields, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T14:48:28.341497Z","iopub.execute_input":"2025-09-27T14:48:28.341920Z","iopub.status.idle":"2025-09-27T14:48:28.365711Z","shell.execute_reply.started":"2025-09-27T14:48:28.341899Z","shell.execute_reply":"2025-09-27T14:48:28.364664Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Create test dataset without labels for prediction\nclass TestDataset(Dataset):\n    def __init__(self, texts, tokenizer, max_length=512):\n        self.texts = texts\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        inputs = self.tokenizer(\n            text,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_length,\n            return_tensors='pt'\n        )\n        \n        return {\n            'input_ids': inputs['input_ids'].flatten(),\n            'attention_mask': inputs['attention_mask'].flatten(),\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T14:48:28.366676Z","iopub.execute_input":"2025-09-27T14:48:28.366983Z","iopub.status.idle":"2025-09-27T14:48:28.373444Z","shell.execute_reply.started":"2025-09-27T14:48:28.366952Z","shell.execute_reply":"2025-09-27T14:48:28.372608Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\"/kaggle/input/modernbert-base-trained/pytorch/default/1/model\")\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/modernbert-base-trained/pytorch/default/1/model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T14:48:28.374280Z","iopub.execute_input":"2025-09-27T14:48:28.374589Z","iopub.status.idle":"2025-09-27T14:48:52.553092Z","shell.execute_reply.started":"2025-09-27T14:48:28.374568Z","shell.execute_reply":"2025-09-27T14:48:52.552073Z"}},"outputs":[{"name":"stderr","text":"2025-09-27 14:48:35.758717: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758984515.969364      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758984516.032260      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Create test dataset without labels\ntest_dataset = TestDataset(test_df['combined_text'].tolist(), tokenizer)\n\n# Custom prediction function\ndef predict_with_model(model, test_dataset, batch_size=16):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    model.eval()\n    \n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n    all_predictions = []\n    \n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=\"Predicting\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            \n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n            \n            probs = torch.sigmoid(logits).cpu().numpy()\n            all_predictions.extend(probs.flatten())\n    \n    return all_predictions\n\n# Get predictions\npredictions = predict_with_model(model, test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T14:48:52.554051Z","iopub.execute_input":"2025-09-27T14:48:52.554734Z","iopub.status.idle":"2025-09-27T14:49:11.264363Z","shell.execute_reply.started":"2025-09-27T14:48:52.554708Z","shell.execute_reply":"2025-09-27T14:49:11.263489Z"}},"outputs":[{"name":"stderr","text":"Predicting: 100%|██████████| 1/1 [00:18<00:00, 18.69s/it]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Create submission file\nsubmission = pd.DataFrame({\n    'row_id': test_df['row_id'],\n    'rule_violation': predictions\n})\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Submission file created successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T14:49:11.266208Z","iopub.execute_input":"2025-09-27T14:49:11.266493Z","iopub.status.idle":"2025-09-27T14:49:11.280270Z","shell.execute_reply.started":"2025-09-27T14:49:11.266472Z","shell.execute_reply":"2025-09-27T14:49:11.279250Z"}},"outputs":[{"name":"stdout","text":"Submission file created successfully!\n","output_type":"stream"}],"execution_count":7}]}