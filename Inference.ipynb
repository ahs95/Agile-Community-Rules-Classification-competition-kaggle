{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"sourceType":"competition"},{"sourceId":593444,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":442749,"modelId":459283}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-01T06:39:47.658161Z","iopub.execute_input":"2025-10-01T06:39:47.658322Z","iopub.status.idle":"2025-10-01T06:39:48.870103Z","shell.execute_reply.started":"2025-10-01T06:39:47.658306Z","shell.execute_reply":"2025-10-01T06:39:48.869346Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/jigsaw-agile-community-rules/sample_submission.csv\n/kaggle/input/jigsaw-agile-community-rules/train.csv\n/kaggle/input/jigsaw-agile-community-rules/test.csv\n/kaggle/input/modernbert-base-trained/pytorch/default/3/model/config.json\n/kaggle/input/modernbert-base-trained/pytorch/default/3/model/training_args.bin\n/kaggle/input/modernbert-base-trained/pytorch/default/3/model/tokenizer.json\n/kaggle/input/modernbert-base-trained/pytorch/default/3/model/tokenizer_config.json\n/kaggle/input/modernbert-base-trained/pytorch/default/3/model/model.safetensors\n/kaggle/input/modernbert-base-trained/pytorch/default/3/model/special_tokens_map.json\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\nfrom tqdm import tqdm\nimport re","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T06:39:48.870742Z","iopub.execute_input":"2025-10-01T06:39:48.871016Z","iopub.status.idle":"2025-10-01T06:39:58.472534Z","shell.execute_reply.started":"2025-10-01T06:39:48.870998Z","shell.execute_reply":"2025-10-01T06:39:58.471957Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# URL keyword extraction function (same as in training)\ndef url_to_semantics(text):\n    \"\"\"\n    Extract meaningful keywords from URLs in text.\n    \"\"\"\n    if not isinstance(text, str):\n        return \"\"\n    \n    # Regular expression to match URLs\n    url_pattern = re.compile(\n        r'https?://'  # http:// or https://\n        r'(?:www\\.)?'  # optional www.\n        r'([^/?]+)'  # domain (group 1)\n        r'(?:[^/]*)'  # optional TLD and port\n        r'(/[^/?]*)'  # path (group 2)\n    )\n    \n    urls = url_pattern.findall(text)\n    \n    if not urls:\n        return \"\"\n    \n    keywords = []\n    \n    for domain, path in urls:\n        # Clean domain: remove TLD and common prefixes\n        domain = domain.split('.')[0]  # Take first part before dot\n        if domain and domain not in ['www', 'http', 'https']:\n            keywords.append(f\"domain:{domain}\")\n        \n        # Clean path: remove leading slash and split\n        if path and len(path) > 1:  # Ensure path is not just \"/\"\n            path_parts = path.strip('/').split('/')\n            for part in path_parts:\n                # Skip empty parts, numbers, or very short parts\n                if part and not part.isdigit() and len(part) > 2:\n                    # Skip common file extensions\n                    if part.lower() not in ['jpg', 'jpeg', 'png', 'gif', 'html', 'php', 'asp', 'aspx']:\n                        keywords.append(f\"path:{part}\")\n                        break  # Only take the first meaningful path part\n    \n    # Remove duplicates while preserving order\n    seen = set()\n    unique_keywords = []\n    for kw in keywords:\n        if kw not in seen:\n            seen.add(kw)\n            unique_keywords.append(kw)\n    \n    if unique_keywords:\n        return \"URL Keywords: \" + \" \".join(unique_keywords)\n    else:\n        return \"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T06:39:58.474353Z","iopub.execute_input":"2025-10-01T06:39:58.474740Z","iopub.status.idle":"2025-10-01T06:39:58.481664Z","shell.execute_reply.started":"2025-10-01T06:39:58.474721Z","shell.execute_reply":"2025-10-01T06:39:58.480950Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Load test data\ntest_df = pd.read_csv('/kaggle/input/jigsaw-agile-community-rules/test.csv')\n\n# Apply URL keyword extraction\ntest_df[\"body_with_url\"] = test_df[\"body\"].apply(lambda x: x + \" \" + url_to_semantics(x))\n\n# Create combined text with rule and body_with_url\ntest_df['combined_text'] = test_df[\"rule\"] + \"[SEP]\" + test_df[\"body_with_url\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T06:39:58.482347Z","iopub.execute_input":"2025-10-01T06:39:58.482526Z","iopub.status.idle":"2025-10-01T06:39:58.521039Z","shell.execute_reply.started":"2025-10-01T06:39:58.482511Z","shell.execute_reply":"2025-10-01T06:39:58.520379Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Create test dataset\nclass TestDataset(Dataset):\n    def __init__(self, texts, tokenizer, max_length=512):\n        self.texts = texts\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        inputs = self.tokenizer(\n            text,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_length,\n            return_tensors='pt'\n        )\n        \n        return {\n            'input_ids': inputs['input_ids'].flatten(),\n            'attention_mask': inputs['attention_mask'].flatten(),\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T06:39:58.521765Z","iopub.execute_input":"2025-10-01T06:39:58.522024Z","iopub.status.idle":"2025-10-01T06:39:58.526722Z","shell.execute_reply.started":"2025-10-01T06:39:58.522007Z","shell.execute_reply":"2025-10-01T06:39:58.526140Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\"/kaggle/input/modernbert-base-trained/pytorch/default/3/model\")\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/modernbert-base-trained/pytorch/default/3/model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T06:39:58.527332Z","iopub.execute_input":"2025-10-01T06:39:58.527525Z","iopub.status.idle":"2025-10-01T06:40:20.263700Z","shell.execute_reply.started":"2025-10-01T06:39:58.527510Z","shell.execute_reply":"2025-10-01T06:40:20.262673Z"}},"outputs":[{"name":"stderr","text":"2025-10-01 06:40:05.426904: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759300805.715125      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759300805.797260      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Create test dataset\ntest_dataset = TestDataset(test_df['combined_text'].tolist(), tokenizer)\n\n# Prediction function\ndef predict_with_model(model, test_dataset, batch_size=16):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    model.eval()\n    \n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n    all_predictions = []\n    \n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=\"Predicting\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            \n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n            \n            # For binary classification, get probability of positive class\n            probs = torch.softmax(logits, dim=-1)[:, 1].cpu().numpy()\n            all_predictions.extend(probs)\n    \n    return all_predictions\n\n# Get predictions\npredictions = predict_with_model(model, test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T06:40:20.265066Z","iopub.execute_input":"2025-10-01T06:40:20.265727Z","iopub.status.idle":"2025-10-01T06:40:34.735027Z","shell.execute_reply.started":"2025-10-01T06:40:20.265698Z","shell.execute_reply":"2025-10-01T06:40:34.734414Z"}},"outputs":[{"name":"stderr","text":"Predicting:   0%|          | 0/1 [00:00<?, ?it/s]W1001 06:40:33.321000 36 torch/_inductor/utils.py:1137] [1/0] Not enough SMs to use max_autotune_gemm mode\nPredicting: 100%|██████████| 1/1 [00:08<00:00,  8.43s/it]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Create submission file\nsubmission = pd.DataFrame({\n    'row_id': test_df['row_id'],\n    'rule_violation': predictions\n})\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Submission file created successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T06:40:34.735830Z","iopub.execute_input":"2025-10-01T06:40:34.736124Z","iopub.status.idle":"2025-10-01T06:40:34.746524Z","shell.execute_reply.started":"2025-10-01T06:40:34.736098Z","shell.execute_reply":"2025-10-01T06:40:34.745904Z"}},"outputs":[{"name":"stdout","text":"Submission file created successfully!\n","output_type":"stream"}],"execution_count":8}]}